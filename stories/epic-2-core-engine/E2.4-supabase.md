# E2.4: Supabase Integration

**Epic:** E2 - Core Scraping Engine
**Story ID:** E2.4
**Story Points:** 5
**Priority:** P0 (Critical)
**Type:** Feature
**Status:** âœ… Complete

---

## User Story

**As a** developer
**I want to** store normalized events in Supabase Postgres
**So that** data persists for caching and retrieval

---

## Acceptance Criteria

- [x] Implement `src/storage/supabase.py` with `SupabaseClient` class
- [x] Load credentials from `.env` (SUPABASE_URL, SUPABASE_KEY)
- [x] Connect to Postgres using `psycopg2`
- [x] Implement `upsert_events(events: List[NormalizedEvent])`
  - SQL: INSERT ... ON CONFLICT ... DO UPDATE
  - Handle conflict on `(source_name, source_event_id)`
  - Update `scraped_at` timestamp on conflict
  - Batch insert (single transaction)
- [x] Implement `get_cached_events(source_name, ttl_hours=6)`
  - Query by source, filter by `scraped_at > NOW() - INTERVAL`
  - Return list of event dicts
- [x] Test connection on init (fail fast if unreachable)
- [x] Log SQL errors with context
- [x] Integration test with real Supabase instance

---

## UPSERT SQL

```sql
INSERT INTO events (
  title, description, event_date, venue, city_area,
  source_name, source_url, source_event_id, content_hash,
  age_range, price, is_free, quality_score, scraped_at
) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
ON CONFLICT (source_name, source_event_id)
DO UPDATE SET
  title = EXCLUDED.title,
  description = EXCLUDED.description,
  event_date = EXCLUDED.event_date,
  venue = EXCLUDED.venue,
  city_area = EXCLUDED.city_area,
  age_range = EXCLUDED.age_range,
  price = EXCLUDED.price,
  is_free = EXCLUDED.is_free,
  quality_score = EXCLUDED.quality_score,
  scraped_at = NOW();
```

---

## Dependencies

**Depends on:** E2.3 (Normalizer)
**Blocks:** E2.5 (Cache Layer), E2.6 (Orchestrator)

---

## Definition of Done

- [x] Events saved to Supabase successfully
- [x] UPSERT prevents duplicates (same run)
- [x] Cache query returns correct events
- [x] Integration test passes
- [x] Connection errors handled gracefully

---

## Technical Notes

Database credentials from `.env`:
```
SUPABASE_URL=https://[project].supabase.co
SUPABASE_KEY=[anon_key]
```

Existing table should already have proper schema and indexes.

---

**Created:** 2025-10-07
**Last Updated:** 2025-10-07
**Completed:** 2025-10-07

---

## Dev Agent Record

### Completion Notes
- Implemented SupabaseClient with psycopg2 connection management
- UPSERT logic using execute_values for efficient batch operations
- Conflict resolution on (source_name, source_event_id) composite key
- Cache retrieval with configurable TTL (default 6 hours)
- Context manager support for proper resource cleanup
- All 6 unit tests passing (mocked for database interactions)
- Comprehensive error handling and logging
