# E3.5: Data Quality Validation

**Epic:** E3 - Multi-Source Integration
**Story ID:** E3.5
**Story Points:** 3
**Priority:** P1 (High)
**Type:** Feature
**Status:** ⏸️ Blocked

---

## User Story

**As a** developer
**I want to** flag low-quality events
**So that** users can filter or deprioritize incomplete data

---

## Acceptance Criteria

- [ ] Define quality score algorithm (0-100)
  - Required fields present (+20 each): title, date, description
  - Optional fields present (+10 each): venue, age_range, price
  - Description length > 50 chars (+10)
  - Future event (not past) (+10)
- [ ] Add `quality_score` field to normalized events
- [ ] Log quality statistics (avg score, % low-quality events)
- [ ] Option to filter events below quality threshold
- [ ] Unit test scoring algorithm

---

## Quality Tiers

- **High:** 80-100 (complete metadata)
- **Medium:** 50-79 (missing some fields)
- **Low:** 0-49 (minimal data, consider excluding)

---

## Dependencies

**Depends on:** E3.3 (Deduplication)
**Blocks:** Epic 5 (Slash Command - needs quality filtering)

---

## Definition of Done

- [ ] Quality score calculated for all events
- [ ] Low-quality events flagged in logs
- [ ] Can filter by minimum quality score
- [ ] Unit tests pass
- [ ] Statistics logged per scraping run

---

## Technical Notes

Quality scoring should be integrated into the normalizer (E2.3), but this story adds filtering and reporting capabilities.

Example log output:
```
[INFO] Quality stats: Avg=72, High=65%, Med=30%, Low=5%
[WARN] 12 events below quality threshold (score < 50)
```

---

**Created:** 2025-10-07
**Last Updated:** 2025-10-07
