# E3.4: Parallel Scraping with Timeout

**Epic:** E3 - Multi-Source Integration
**Story ID:** E3.4
**Story Points:** 3
**Priority:** P1 (High)
**Type:** Feature
**Status:** ⏸️ Blocked

---

## User Story

**As a** developer
**I want to** scrape multiple sources concurrently
**So that** total execution time is minimized

---

## Acceptance Criteria

- [ ] Update `EventOrchestrator` to use `concurrent.futures.ThreadPoolExecutor`
- [ ] Launch scraper threads in parallel (max workers = # sources)
- [ ] Set timeout per source (30 seconds default, configurable)
- [ ] If source times out: Log warning, continue with other sources
- [ ] If source errors: Log error, continue with other sources
- [ ] Aggregate results from successful sources
- [ ] Log execution summary (which sources succeeded/failed, total time)
- [ ] Integration test: Mock slow source, verify timeout works

---

## Expected Behavior

```bash
$ python -m src.orchestrator --sources knco,library,county
[INFO] Scraping 3 sources in parallel...
[INFO] knco completed in 2.3s (200 events)
[INFO] library completed in 1.8s (30 events)
[WARN] county timed out after 30s (0 events)
[SUCCESS] Total: 230 events from 2/3 sources
```

---

## Dependencies

**Depends on:** E3.1 (Library Scraper), E3.2 (County Scraper)
**Blocks:** None (can run in parallel with E3.5)

---

## Definition of Done

- [ ] Multiple scrapers run in parallel
- [ ] Timeout prevents hanging
- [ ] Graceful failure for individual sources
- [ ] Total execution time < 30 seconds
- [ ] Integration test passes

---

## Technical Notes

Use Python's `concurrent.futures.ThreadPoolExecutor`:
```python
from concurrent.futures import ThreadPoolExecutor, TimeoutError

with ThreadPoolExecutor(max_workers=3) as executor:
    futures = {executor.submit(scraper.scrape): scraper.name
               for scraper in scrapers}
    # Wait with timeout, handle results
```

---

**Created:** 2025-10-07
**Last Updated:** 2025-10-07
