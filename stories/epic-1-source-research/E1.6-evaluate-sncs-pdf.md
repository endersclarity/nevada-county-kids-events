# E1.6: Evaluate SNCS PDF Calendar Scraping

**Epic:** E1 - Source Research & Evaluation
**Story ID:** E1.6
**Story Points:** 2
**Priority:** P2 (Low - Post-MVP)
**Type:** Research/Spike
**Status:** ✅ Complete - Ready for Review

---

## User Story

**As a** developer
**I want to** evaluate PDF-to-text extraction for SNCS calendars using CLI tools
**So that** I can determine if automated PDF scraping is viable as a 3rd MVP source

---

## Acceptance Criteria

- [x] Download sample SNCS PDF calendar (TLCOct25.pdf or Playgroups2024.pdf)
- [x] Test CLI extraction tools (pdftotext, Marker, or Docling)
- [x] Extract text/markdown from PDF successfully
- [x] Count actual event volume in sample PDF (need ≥20 events for viability)
- [x] Document parsing complexity (can events be extracted with regex?)
- [x] Calculate scraping difficulty (1-5 scale) with CLI tools
- [x] Store findings in `docs/source-evaluation.md` (SNCS PDF section)

---

## Technical Tasks

1. **Setup CLI Tools**
   - Install one of: pdftotext (Poppler), Marker, or Docling CLI
   - Test on sample SNCS PDF
   - Compare output quality (layout preservation, table handling)

2. **Extract Sample PDF**
   - Download: https://www.sncs.org/PDFs/LearningCenter/TLCOct25.pdf
   - Extract text/markdown
   - Count total events in calendar

3. **Assess Parsing Feasibility**
   - Analyze PDF structure (consistent format? tables? multi-column?)
   - Test regex patterns for event extraction
   - Identify fields: title, date, time, location, age range, cost
   - Document parsing complexity

4. **Calculate ROI**
   - Event volume: How many events/month?
   - Build time estimate: Initial scraper + parsing logic
   - Maintenance time: Monthly PDF URL updates, format changes
   - Compare to manual entry (15 min/month for 10 events)

5. **Make Recommendation**
   - Add to MVP: If ≥30 events/month AND parsing straightforward
   - Defer to Post-MVP: If 15-30 events/month OR parsing complex
   - Skip: If <15 events/month OR unparseable format

---

## Technical Notes

### Context
- **Discovery:** SNCS publishes monthly PDF calendars (found in E1.5)
- **Original assessment:** 5/5 difficulty (PDF extraction + parsing)
- **Re-evaluation trigger:** CLI tools (pdftotext, Marker, Docling) are more reliable than Python libraries
- **Expected volume:** 10-30 events/month (based on Adventure Mama's listings)

### CLI Tools to Evaluate

**Option 1: pdftotext (Poppler)**
```bash
# Maintain layout
pdftotext -layout TLCOct25.pdf output.txt

# Pros: Fast, reliable, handles complex layouts
# Cons: Plain text output (not markdown)
```

**Option 2: Marker**
```bash
# Convert to markdown
marker TLCOct25.pdf --output_format markdown

# Pros: Markdown output, good for RAG pipelines
# Cons: Newer tool, may require more dependencies
```

**Option 3: Docling CLI**
```bash
# Convert with advanced parsing
docling convert TLCOct25.pdf --output markdown

# Pros: Best layout/table handling, OCR support
# Cons: Heaviest (ML models), slowest
```

### Parsing Challenges

**Expected event format in PDF:**
```
Play and Learn
Tuesdays and Wednesdays, 9:30-11:00am
Ages 0-5, $10 per session

Parents Circle
Wednesdays, 3:00pm
Free, drop-in welcome
```

**Parsing requirements:**
- Extract recurring days → map to specific dates in October
- Parse time ranges (9:30-11:00am)
- Extract age ranges (0-5)
- Extract cost information ($10, Free)
- Handle multi-line event descriptions

**Complexity factors:**
- PDF format consistency month-to-month
- Table layouts vs paragraph layouts
- Multi-column pages
- Page breaks in middle of events

### ROI Breakeven Analysis

| Events/Month | Manual Entry (annual) | Automated (annual) | Winner |
|--------------|----------------------|-------------------|---------|
| 10 | 3 hours | 10 hours | Manual |
| 20 | 6 hours | 10 hours | Manual |
| 30 | 9 hours | 10 hours | Automation |
| 50+ | 15+ hours | 10 hours | Automation |

**Assumptions:**
- Manual: 15 min/month to copy/paste events
- Automated: 4-5 hours initial build + 30 min/month maintenance

### Known Event Types from SNCS

From previous research and Adventure Mama's lists:
- Play and Learn (recurring playgroup)
- Parents Circle (support group)
- SNCS Open Play Daily
- The Nest Hatchlings
- Learning Center programs (unknown volume)
- Wiggles & Giggles (Sierra County)

**Question:** Are these 5-6 recurring programs OR 20-30 individual dated events?

---

## Dependencies

**Depends on:**
- E1.5 (PARTNERS FRC evaluation) - Complete (identified SNCS as individual org)
- E1.4 (Prioritization) - Done

**Blocks:**
- Potential E2.3 story: "Build SNCS PDF Scraper" (if evaluation positive)
- Decision on 3rd MVP source

---

## Definition of Done

- [x] CLI tool selected and tested on sample SNCS PDF
- [x] Text/markdown extracted successfully
- [x] Actual event count documented (not estimated)
- [x] Parsing complexity assessed (regex patterns tested)
- [x] Scraping difficulty scored (1-5 with CLI tools)
- [x] ROI calculation complete (automation vs manual)
- [x] Recommendation made: Add to MVP, defer to Post-MVP, or skip
- [x] Findings documented in `docs/source-evaluation.md`

---

## Decision Criteria

**Add to MVP (Build E2.3 scraper) if:**
- Event volume ≥ 30/month
- PDF format is consistent and parseable
- Scraping difficulty ≤ 3/5 with CLI tools
- Unique events (minimal overlap with Library calendar)

**Defer to Post-MVP if:**
- Event volume 15-30/month (marginal ROI)
- Parsing is complex but doable (3-4/5 difficulty)
- User feedback needed to prioritize

**Skip entirely if:**
- Event volume < 15/month (manual entry faster)
- PDF format is unparseable or highly variable
- Scraping difficulty 4-5/5 (complex custom logic required)
- High overlap with Library calendar (duplicate content)

---

## Success Metrics

**What "success" looks like:**
- Clear yes/no decision on SNCS PDF scraping viability
- Accurate event volume (not estimated)
- Working proof-of-concept extraction (actual PDF → parsed events)
- Realistic time estimates for implementation

**Deliverables:**
- Sample PDF text extraction (output.txt or output.md)
- Event count and classification
- Parsing pattern examples (regex or code snippets)
- Updated source-evaluation.md with SNCS section

---

## Notes

**Why this matters:**
- SNCS events are Adventure Mama's primary "unique content" gap
- ~50% of her events come from community playgroups (SNCS, The Nest, etc.)
- If SNCS scraping is viable, pattern applies to other PDF-based sources

**Why we're re-evaluating:**
- Original E1.5 rated PARTNERS FRC as 5/5 difficulty
- CLI tools (pdftotext, Marker, Docling) reduce difficulty to ~2.5/5
- Small effort investment (2-3 hours) could unlock significant value

**Risk mitigation:**
- This is a **time-boxed research spike** (2 story points = 2-3 hours max)
- If PDF is unparseable after 2 hours → recommendation is "skip"
- Don't over-invest in custom parsing logic during evaluation

**Alternative if rejected:**
- Community event submission form (Epic 7)
- SNCS partnership (request email notifications)
- Adventure Mama collaboration

---

## Dev Agent Record

### Debug Log
```
2025-10-07: E1.6 SNCS PDF Evaluation Execution

Plan:
1. Download sample PDFs from SNCS website
2. Test pdftotext CLI tool for extraction
3. Count actual events in sample calendars
4. Assess parsing complexity with regex patterns
5. Calculate scraping difficulty score
6. Document findings in source-evaluation.md

Execution:
- Downloaded TLCOct25.pdf (Learning Center calendar) - 448KB
- Downloaded SNCS_Workshops_0725-1225.pdf (Workshops) - 541KB
- Playgroups2024.pdf corrupted (630 bytes, not a valid PDF)
- Used pdftotext with -layout flag for clean extraction
- TLC calendar: 0 events (availability schedule only, not discrete events)
- Workshops calendar: 6 events over 6 months (1 event/month avg)
- Tested regex patterns for date extraction (multiple format variations)
- Identified parsing complexity: 2.5/5 (medium-low difficulty)

Critical Finding:
- SNCS PDFs contain adult professional development workshops, NOT kid events
- Target audience: childcare providers, educators (not parents/families)
- Kid-relevance: 0% - wrong audience entirely
- Event volume: 1/month (far below 30/month automation threshold)
- ROI: Manual entry 25x faster (24 min/year vs 10 hours/year)

Recommendation: SKIP - Zero kid-relevance invalidates all other metrics
```

### Completion Notes
**Story E1.6 completed successfully with clear recommendation: SKIP**

**Key outcomes:**
1. ✅ Evaluated 2 SNCS PDF calendars (TLC and Workshops)
2. ✅ CLI extraction tested and working (pdftotext)
3. ✅ Actual event count: 6 workshops over 6 months (not estimated)
4. ✅ Parsing difficulty: 2.5/5 (date format variations manageable)
5. ❌ Kid-relevance: 0% - adult professional development only

**Decision rationale:**
- Primary: Wrong target audience (childcare professionals, not families)
- Secondary: Event volume too low (1/month vs 30/month threshold)
- Tertiary: ROI strongly negative (manual entry 25x faster)

**Documentation deliverables:**
- Comprehensive SNCS section added to `docs/source-evaluation.md`
- Includes: event volume, metadata completeness, parsing complexity, ROI analysis
- Recommendation: Do not implement scraper
- Alternative approaches documented (email notifications, community forms)

**Extracted files saved:**
- `temp/sncs-pdf/TLCOct25.pdf` - Learning Center calendar (Oct 2025)
- `temp/sncs-pdf/SNCS_Workshops_0725-1225.pdf` - Workshops (Jul-Dec 2025)
- `temp/sncs-pdf/TLCOct25.txt` - Extracted text from TLC calendar
- `temp/sncs-pdf/SNCS_Workshops.txt` - Extracted text from workshops PDF

**Time investment:** ~1.5 hours (within 2 story point budget)

**Follow-up actions:**
- None required for SNCS (recommendation is to skip)
- Pattern validates CLI tools for future PDF sources (if needed)
- Re-evaluate only if SNCS publishes family events calendar (≥15 events/month)

---

## File List

**Modified:**
- `workflows/nevada-county-kids-events/docs/source-evaluation.md` - Added SNCS PDF evaluation section

**Created:**
- `temp/sncs-pdf/TLCOct25.pdf` - Sample SNCS Learning Center calendar (Oct 2025)
- `temp/sncs-pdf/SNCS_Workshops_0725-1225.pdf` - Sample SNCS Workshops calendar (Jul-Dec 2025)
- `temp/sncs-pdf/TLCOct25.txt` - Extracted text from TLC calendar
- `temp/sncs-pdf/SNCS_Workshops.txt` - Extracted text from workshops calendar
- `temp/sncs-pdf/parse_test.py` - Initial regex parsing test (temporary)
- `temp/sncs-pdf/parse_test2.py` - Improved event parsing test (temporary)
- `temp/sncs-pdf/manual_count.py` - Manual event counting analysis (temporary)
- `temp/validation_check.md` - Acceptance criteria validation checklist (temporary)

---

## Change Log

**2025-10-07 - E1.6 SNCS PDF Evaluation Complete**
- Evaluated SNCS PDF calendars for scraping viability
- Downloaded and extracted 2 sample PDFs (TLC calendar, Workshops schedule)
- Tested pdftotext CLI tool successfully for PDF-to-text extraction
- Counted actual events: 0 (TLC), 6 (Workshops) over 6 months
- Assessed parsing complexity: 2.5/5 difficulty (date format variations)
- Calculated ROI: Manual entry 25x faster than automation
- **Critical finding:** SNCS events are adult professional development, not kid activities
- **Recommendation:** SKIP - Zero kid-relevance, wrong target audience
- Added comprehensive SNCS section to `docs/source-evaluation.md`
- Documented alternative approaches (email notifications, community forms)
- Marked all acceptance criteria and DoD items as complete

---

**Created:** 2025-10-07
**Last Updated:** 2025-10-07
**Status:** ✅ Complete - Ready for Review
